{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "victorian-rebound",
   "metadata": {},
   "source": [
    "# Randomized Controlled Trials discussion questions\n",
    "\t• What is a Randomized Controlled Trial (RCT)? When/where are RCTs used?\n",
    "    \n",
    "    Experimental design where we randomly assign subjects to experiment or control groups. \n",
    "    Economics, clinical research, engineering.     \n",
    "    \n",
    "\t• Why randomization in scientific trials? What is the objective of an RCT? Tip: think statistics.\n",
    "    \n",
    "    Removing influence of bias and variation on measurement of experiment/placebo effects. \n",
    "    The objective of an RCT is to make the statistics (eg. moments) of the two groups as similar as possible, while getting good variation among the groups.   \n",
    "    \n",
    "\t• Can we use optimization to improve outcomes of an RCT? How? What is the form of the problem?\n",
    "    We can do optimization over moments, using data about participants to assign them. \n",
    "    The trick is mixed-integer optimization (MIO).  \n",
    "    \n",
    "\t• How can uncertainty play a role in RCTs, or \"optimized\" experimental design (OED)?\n",
    "    \n",
    "    In other words, where could uncertainty come from (let's assume we are doing experimental design for Covid vaccine trials):\n",
    "    - Measurement error in patient features. \n",
    "    - Misreporting error. \n",
    "    - Interpolation of omitted values (if we do imputation). \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-approval",
   "metadata": {},
   "source": [
    "# Robust Optimal Experiments\n",
    "\n",
    "The Randomized Controlled Trial (RCT) is a trusted method in experimental design that aims to figure out responses to certain interventions, while reducing the discrepancy in results due to variance in subjects. In fact, in 2019, Prof. Duflo and Banerjee from MIT got the Nobel Prize in Economics for using RCTs for addressing issues in development economics (esp. poverty and availability of healthcare) using RCTs. \n",
    "\n",
    "But very few people talked about the fact that RCTs are quite ineffective in several aspects:\n",
    "- They rely on the Law of Large Numbers, and large experimental populations are expensive. \n",
    "- For small samples, they are bad in achieving \"uniform randomness\" in the experimental groups. \n",
    "\n",
    "Instead, there is research to suggest that **optimal** experimental design (OED) can be significantly more powerful. \n",
    "\n",
    "This lecture will hopefully demonstrate that randomization is NOT a reliable method for getting the right distribution of \"features\" in subjects. Furthermore, it will demonstrate the influence of robustness on OEDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-jerusalem",
   "metadata": {},
   "source": [
    "## Motivational Problem: Medical Trials\n",
    "\n",
    "Suppose that we only have the budget to conduct initial Covid-19 vaccine trials on 10 patients, where the patients are split 50/50 between control and treatment groups. We have had 20 applicants with 5 traits, which we generate randomly. (We have chosen small numbers since this problem can quickly become computationally challenging. But it is definitely solvable in larger scale as well.)\n",
    "\n",
    "For simplicity, we will only consider the diagonal of the covariance matrix in recitation. However, this method can be extended to the full covariance matrix, by adding a lot more variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "using JuMP, Distributions, Random, LinearAlgebra, Gurobi, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_random_people(n_people::Int64 = 20, n_traits::Int64 = 5)\n",
    "    # NOTE THAT OUR DATA IS NORMALIZED, so it makes the formulation more straight-forward. \n",
    "    continuous_values = rand(MersenneTwister(314), Normal(0.00, 1), (n_people, n_traits))\n",
    "    return continuous_values\n",
    "end\n",
    "n_groups = 2\n",
    "n_patients = 10\n",
    "n_people = 20\n",
    "n_traits = 5\n",
    "data = generate_random_people(20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first try randomization\n",
    "ctrl_idxs = Int64.(collect(1:n_patients/2))\n",
    "vacc_idxs = Int64.(collect(n_patients/2+1:n_patients))\n",
    "function print_details(data, ctrl_idxs, vacc_idxs)\n",
    "    println(\"Control group: \", ctrl_idxs)\n",
    "    println(\"Vaccine group: \", vacc_idxs)\n",
    "    println(\"Mean traits of control group: \", round.(mean(data[ctrl_idxs, :], dims=1); sigdigits = 4))\n",
    "    println(\"Mean traits of vaccine group: \", round.(mean(data[vacc_idxs, :], dims=1); sigdigits = 4))\n",
    "    println(\"Var of traits of control group: \", round.(var(data[ctrl_idxs, :], dims=1); sigdigits = 4))\n",
    "    println(\"Var of traits of vaccine group: \", round.(var(data[vacc_idxs, :], dims=1); sigdigits = 4))\n",
    "    println(\"Nominal objective: \", round.(sum(abs.(mean(data[ctrl_idxs, :], dims=1) - mean(data[vacc_idxs, :], dims=1))) + \n",
    "            0.5 * sum(abs.(var(data[ctrl_idxs, :], dims=1) - var(data[vacc_idxs, :], dims=1))); sigdigits = 4))\n",
    "    return\n",
    "end\n",
    "print_details(data, ctrl_idxs, vacc_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the errors\n",
    "function plot_errors(data, ctrl_idxs, vacc_idxs)\n",
    "    l = @layout [a ; b]\n",
    "    p1 = bar(collect(1:n_traits), mean(data[ctrl_idxs, :], dims=1)' .-  mean(data[vacc_idxs, :], dims=1)', label = \"Mean errors\")\n",
    "    p2 = bar(collect(1:n_traits), var(data[ctrl_idxs, :], dims=1)' .- var(data[vacc_idxs, :], dims=1)', label = \"Variance errors\")\n",
    "    plt = plot(p1, p2, layout = l)\n",
    "    return plt\n",
    "end\n",
    "plt = plot_errors(data, ctrl_idxs, vacc_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-explorer",
   "metadata": {},
   "source": [
    "### Can Optimization do better? \n",
    "It sure can! Let's start by writing out the problem. \n",
    "\n",
    "In this case, we will pick 2 groups of equal numbers of patients from the population, while minimizing the L1-norm error in the mean and variances between the two groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start creating out model, and trying to solve without uncertainty\n",
    "m = Model(Gurobi.Optimizer)\n",
    "set_optimizer_attribute(m, \"OutputFlag\", 0)\n",
    "@variable(m, x[i=1:n_people, 1:n_groups], Bin)\n",
    "@variable(m, μ_p[i=1:n_groups, j=1:n_traits]) # Mean\n",
    "@variable(m, σ_p[i=1:n_groups, j=1:n_traits]) # Variance\n",
    "for j = 1:n_groups # Taking the mean and std deviation of parameters for each group\n",
    "    @constraint(m, μ_p[j,:] .== 1/(n_patients/n_groups) * \n",
    "                    sum(data[i,:] .* x[i,j] for i=1:n_people)) # computing means\n",
    "    @constraint(m, σ_p[j,:] .== 1/(n_patients/n_groups) * \n",
    "                    sum(data[i,:].^2 .* x[i,j] for i=1:n_people)) # computing variances\n",
    "    @constraint(m, sum(x[:,j]) == n_patients/n_groups)\n",
    "end\n",
    "for i = 1:n_people\n",
    "    @constraint(m, sum(x[i, :]) <= 1) # each patient only picked at most once\n",
    "end\n",
    "\n",
    "@variable(m, d)\n",
    "@variable(m, M[1:n_traits]) # mean error\n",
    "@variable(m, V[1:n_traits]) # variance error\n",
    "rho = 0.5\n",
    "@objective(m, Min, sum(M) + rho*sum(V))\n",
    "for i = 1:n_groups\n",
    "    for j = i+1:n_groups\n",
    "        @constraint(m, M[:] .>= μ_p[i,:] - μ_p[j,:])\n",
    "        @constraint(m, M[:] .>= μ_p[j,:] - μ_p[i,:])\n",
    "        @constraint(m, V[:] .>= σ_p[i, :] - σ_p[j, :])\n",
    "        @constraint(m, V[:] .>= σ_p[j, :] - σ_p[i, :])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize!(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the results\n",
    "ctrl_opt = findall(x -> x == 1, Array(value.(x[:,1])))\n",
    "vacc_opt = findall(x -> x == 1, Array(value.(x[:,2])))\n",
    "print_details(data, ctrl_opt, vacc_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plot_errors(data, ctrl_opt, vacc_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-presentation",
   "metadata": {},
   "source": [
    "#### Important note: We are not limited to this objective function!\n",
    "For example, we could try maximizing variance while keeping the mean variation below a threshold... you can try any combination that is bounded from below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-france",
   "metadata": {},
   "source": [
    "### How does Robust Optimization (RO) change our solutions? \n",
    "It sure can! Let's start by writing out the problem. \n",
    "\n",
    "Note that we have to embed our uncertainty in our errors instead of the mean and variance variables. This is because putting uncertain variables in an equality is equivalent to collapsing the feasible set to a point, as you saw in the first question of Homework 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start creating out model, and trying to solve with uncertainty\n",
    "rm = Model(Gurobi.Optimizer)\n",
    "# Let's start creating out model, and trying to solve without uncertainty\n",
    "@variable(rm, x[i=1:n_people, 1:n_groups], Bin)\n",
    "@variable(rm, μ_p[i=1:n_groups, j=1:n_traits]) # Mean\n",
    "@variable(rm, σ_p[i=1:n_groups, j=1:n_traits]) # Variance\n",
    "ρ = 0.1\n",
    "Γ = 2\n",
    "# With the following budget uncertainty\n",
    "# @uncertain(rm, ell[1:n_people, 1:n_traits])\n",
    "# @constraint(rm, norm(ell, 1) <= Γ)\n",
    "# @constraint(rm, -ρ .<= ell .<= ρ)  \n",
    "for j = 1:n_groups # Taking the mean and std deviation of parameters for each group\n",
    "    @constraint(rm, μ_p[j,:] .== 1/(n_patients/n_groups) * \n",
    "                    sum(data[i,:].*x[i,j] for i=1:n_people))\n",
    "    @constraint(rm, σ_p[j,:] .== 1/(n_patients/n_groups) * \n",
    "                    sum(data[i,:].^2 .* x[i,j] for i=1:n_people))\n",
    "    @constraint(rm, sum(x[:,j]) == n_patients/n_groups)\n",
    "end\n",
    "for i = 1:n_people\n",
    "    @constraint(rm, sum(x[i, :]) <= 1)\n",
    "end\n",
    "@variable(rm, M[1:n_traits])\n",
    "@variable(rm, V[1:n_traits])\n",
    "@objective(rm, Min, sum(M) + 0.5*sum(V))\n",
    "# Let's use the robust counterpart\n",
    "for i = 1:n_groups # We embed the uncertainty in the errors!\n",
    "    for j = i+1:n_groups\n",
    "        for l = 1:n_traits\n",
    "            y = @variable(rm, [1:n_traits])\n",
    "            normdummy = @variable(rm, [1:n_traits])\n",
    "            @constraint(rm, normdummy .>= y)\n",
    "            @constraint(rm, normdummy .>= -y)\n",
    "            infdummy = @variable(rm)\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= (x[k,j] - x[k,i] - y[k]))\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= -(x[k,j] - x[k,i] - y[k]))\n",
    "            @constraint(rm, M[l] * n_patients/n_groups >= \n",
    "                        sum(data[k,l] .* (x[k,j] - x[k,i]) for k=1:n_people) + \n",
    "                        ρ * sum(normdummy) + Γ*infdummy)\n",
    "            y = @variable(rm, [1:n_traits])\n",
    "            normdummy = @variable(rm, [1:n_traits])\n",
    "            @constraint(rm, normdummy .>= y)\n",
    "            @constraint(rm, normdummy .>= -y)\n",
    "            infdummy = @variable(rm)\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= (x[k,j] - x[k,i] - y[k]))\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= -(x[k,j] - x[k,i] - y[k]))\n",
    "            @constraint(rm, M[l] * n_patients/n_groups >= \n",
    "                        - sum(data[k,l] .* (x[k,j] - x[k,i]) for k=1:n_people) +  \n",
    "                        ρ * sum(normdummy) + Γ*infdummy)\n",
    "#             Sometimes you have to get creative... linearization of the change of the variance. \n",
    "            y = @variable(rm, [1:n_traits])\n",
    "            normdummy = @variable(rm, [1:n_traits])\n",
    "            @constraint(rm, normdummy .>= y)\n",
    "            @constraint(rm, normdummy .>= -y)\n",
    "            infdummy = @variable(rm)\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= (2*data[k,l]*(x[k,j] - x[k,i]) - y[k]))\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= -(2*data[k,l]*(x[k,j] - x[k,i]) - y[k]))\n",
    "            @constraint(rm, V[l] * n_patients/n_groups >= \n",
    "                        sum(data[k,l].^2 .* (x[k,j] - x[k,i]) for k=1:n_people) + \n",
    "                        ρ*sum(normdummy) + Γ*infdummy)\n",
    "            y = @variable(rm, [1:n_traits])\n",
    "            normdummy = @variable(rm, [1:n_traits])\n",
    "            @constraint(rm, normdummy .>= y)\n",
    "            @constraint(rm, normdummy .>= -y)\n",
    "            infdummy = @variable(rm)\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= (2*data[k,l]*(x[k,j] - x[k,i]) - y[k]))\n",
    "            @constraint(rm, [k = 1:n_traits], infdummy >= -(2*data[k,l]*(x[k,j] - x[k,i]) - y[k]))\n",
    "            @constraint(rm, V[l] * n_patients/n_groups >= \n",
    "                        -sum(data[k,l].^2 .* (x[k,j] - x[k,i]) for k=1:n_people) + \n",
    "                        ρ*sum(normdummy) + Γ*infdummy)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize!(rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the results\n",
    "ctrl_ro = findall(x -> x == 1, Array(value.(x[:,1])))\n",
    "vacc_ro = findall(x -> x == 1, Array(value.(x[:,2])))\n",
    "print_details(data, ctrl_ro, vacc_ro)\n",
    "println(\"Robust objective: \", objective_value(rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacf450",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(data, ctrl_ro, vacc_ro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-trail",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "- Optimal experimental design is a useful method to make sure that the moments of our experiment and control groups are similar, while still being representative of the global population. \n",
    "- Uncertainty can result from a variety of factors in experimental designs.\n",
    "- Robust optimal experimental design can improve the efficacy of experiments with small effect on the statistics of the nominal optimized groups. \n",
    "- Robust solutions can be much worse in their worst case values than they are in their nominal outcomes, so they are less conservative than they look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-finding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
